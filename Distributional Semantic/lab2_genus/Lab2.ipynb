{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e55dffe7-0687-45fe-96ba-7d509295dbbf",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      },
      "source": [
        "# Inferenza del Significato da Definizioni utilizzando WordNet\n",
        "\n",
        "## Introduzione:\n",
        "L'esercizio consiste nell'implementare un algoritmo in grado di inferire il concetto descritto da un insieme di definizioni associate ad esso. L'algoritmo che abbiamo sviluppato può essere riassunto nelle seguenti fasi:\n",
        "\n",
        "1. Caricamento del dataset delle definizioni.\n",
        "2. Preelaborazione: tokenizzazione, conversione in minuscolo, lemmatizzazione, rimozione delle stopwords, rimozione della punteggiatura, rimozione dei token non presenti in WordNet, \n",
        "3. Disambiguazione (algoritmo Lesk) e conteggio delle frequenze dei sensi disambiguati.\n",
        "4. Esecuzione dell'algoritmo di esplorazione dei sensi di WordNet:\n",
        "   - (a) Scelta dei candidati \"genus\" (selezionando i sensi più frequenti).\n",
        "   - (b) Per ogni candidato \"genus\", esecuzione di una ricerca in profondità a partire dal sotto-albero del senso \"genus\" che massimizza la similarità con le definizioni.\n",
        "   - (c) Scelta del senso con la massima similarità tra quelli estratti dai vari sotto-alberi dei candidati \"genus\".\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4748f6f7",
      "metadata": {},
      "source": [
        "Librerie e corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "daac6d27-39ff-42da-81b9-162f53a659af",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-16T01:57:30.248460+00:00",
          "start_time": "2023-07-16T01:57:30.089278+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "from statistics import mean\n",
        "from itertools import product, starmap\n",
        "from nltk.corpus import wordnet as wn\n",
        "from collections import Counter\n",
        "\n",
        "# Downloading necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0749c24f",
      "metadata": {},
      "source": [
        "### Data Loading\n",
        "\n",
        "Caricamento del dataset di definizioni relative ai concetti usando la libreria pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "03a7dc84",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>door</th>\n",
              "      <th>ladybug</th>\n",
              "      <th>pain</th>\n",
              "      <th>blurriness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A construction used to divide two rooms, tempo...</td>\n",
              "      <td>small flying insect, typically red with black ...</td>\n",
              "      <td>A feeling of physical or mental distress</td>\n",
              "      <td>sight out of focus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It's an opening, it can be opened or closed.</td>\n",
              "      <td>It is an insect, it has wings, red with black ...</td>\n",
              "      <td>It is a feeling, physical or emotional. It is ...</td>\n",
              "      <td>It is the absence of definite borders, shapele...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An object that divide two room, closing an hol...</td>\n",
              "      <td>An insect that can fly. It has red or orange c...</td>\n",
              "      <td>A felling that couscious beings can experince ...</td>\n",
              "      <td>A sensation felt when you can't see clearly th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Usable for access from one area to another</td>\n",
              "      <td>Small insect with a red back</td>\n",
              "      <td>Concept that describes a suffering living being</td>\n",
              "      <td>Lack of sharpness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                door  \\\n",
              "0  A construction used to divide two rooms, tempo...   \n",
              "1       It's an opening, it can be opened or closed.   \n",
              "2  An object that divide two room, closing an hol...   \n",
              "3         Usable for access from one area to another   \n",
              "\n",
              "                                             ladybug  \\\n",
              "0  small flying insect, typically red with black ...   \n",
              "1  It is an insect, it has wings, red with black ...   \n",
              "2  An insect that can fly. It has red or orange c...   \n",
              "3                       Small insect with a red back   \n",
              "\n",
              "                                                pain  \\\n",
              "0           A feeling of physical or mental distress   \n",
              "1  It is a feeling, physical or emotional. It is ...   \n",
              "2  A felling that couscious beings can experince ...   \n",
              "3    Concept that describes a suffering living being   \n",
              "\n",
              "                                          blurriness  \n",
              "0                                 sight out of focus  \n",
              "1  It is the absence of definite borders, shapele...  \n",
              "2  A sensation felt when you can't see clearly th...  \n",
              "3                                  Lack of sharpness  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def load_dataset(file_path):\n",
        "\n",
        "    try:\n",
        "        data = pd.read_csv(file_path, sep='\\t')\n",
        "        # Rimuovo la prima colonna siccome non la utilizzerò\n",
        "        data = data[data.columns[1:]]\n",
        "        \n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f'Error loading dataset: {e}')\n",
        "        return []\n",
        "    \n",
        "file_path = './TLN-definitions-23.tsv'\n",
        "\n",
        "defs_df = load_dataset(file_path)   \n",
        "defs_df.head(4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dbf4602",
      "metadata": {},
      "source": [
        "### Preprocessing\n",
        "La funzione `preprocess` viene utilizzata per preelaborare i dati di testo. Prende in input una frase ed esegue le seguenti operazioni:\n",
        "\n",
        "1. Tokenizzazione: La frase viene suddivisa in singole parole.\n",
        "2. Rimozione delle stopword: Ogni parola presente nell'elenco delle stopword viene rimossa dalla frase. Le stopword sono parole comuni che non hanno molto significato e vengono spesso rimosse nelle attività di elaborazione del linguaggio naturale.\n",
        "3. Lemmatizzazione: Ogni parola della frase viene lemmatizzata. \n",
        "4. `Filtro` dei sinonimi WordNet: Tutte le parole che non hanno un corrispondente synset (insieme di sinonimi) in WordNet vengono eliminate. Questo perché utilizziamo WordNet per comprendere il contenuto semantico del testo, quindi ogni parola che non è presente in WordNet non ci è utile.\n",
        "\n",
        "La funzione restituisce la frase preelaborata come insieme di parole (Bag Of Words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ea84dc73-cdd6-4e35-af43-5b3c11f1accf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-16T01:58:01.805659+00:00",
          "start_time": "2023-07-16T01:58:01.647491+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bag of words for context 1:  {'go', 'deposit', 'money', 'bank'}\n",
            "Bag of words for context 2:  {'flower', 'wild', 'bank', 'full', 'river'}\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "additional_stopwords = ['\\'s', '’']\n",
        "punctuation = set(string.punctuation)\n",
        "stopwordset = set(stopwords.words('english') + additional_stopwords)\n",
        "\n",
        "\n",
        "def to_lower_case(words):\n",
        "    return words.lower()\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def lemmatize(words):\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word.lower(), pos='v')  # Specify the part-of-speech tag 'v' for verb\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    return [word for word in words if word not in stopwordset]\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    return [word for word in words if word not in punctuation]\n",
        "\n",
        "def filter_contained_in_wd(words):\n",
        "    return {x for x in words if len(wn.synsets(x)) > 0}\n",
        "\n",
        "def preprocess_data(sentence):\n",
        "    words = to_lower_case(sentence)\n",
        "    words = tokenize(words)\n",
        "    words = lemmatize(words)\n",
        "    words = remove_stopwords(words)\n",
        "    words = remove_punctuation(words)\n",
        "    words = filter_contained_in_wd(words)\n",
        "    return words\n",
        "  \n",
        "\n",
        "sentence1 = 'He went to the bank to deposit my money asda'\n",
        "sentence2 = 'The river bank is full of wild flowers'\n",
        "\n",
        "context1_bow = preprocess_data(sentence1)\n",
        "context2_bow = preprocess_data(sentence2)\n",
        "print(\"Bag of words for context 1: \", context1_bow)\n",
        "print(\"Bag of words for context 2: \", context2_bow)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c2fa50f",
      "metadata": {},
      "source": [
        "Utilizzando l'approccio Lesk-based per Word Sense Disambiguation (WSD), identifichiamo il senso corretto per i lemmi estratti dai generi candidati.\n",
        "\n",
        "L'algoritmo Lesk si basa sulla ricerca dei contesti circostanti una parola all'interno di un dizionario come WordNet. Questo contesto viene utilizzato per determinare il significato più appropriato della parola all'interno del contesto specifico in cui viene utilizzata. \n",
        "\n",
        "Non è stato reimplementato l'algoritmo di Lesk ma utilizzo l'implementazione presente in nltk. Ho comunque caricato il file di esercitazione relativo alla Word Sense Disambiguation dove ho realizzato e descritto in dettaglio l'implementazione di Lesk per il laboratorio della seconda parte del corso.  \n",
        "\n",
        "`nota` Relativo al task della Word Sense Disambiguation, utilizzeremo l'euristica della \"frequenza\" per identificare le word più importanti, selezionando solo queste per limitare la ricerca di sensi.\n",
        "\n",
        "\n",
        "`nota 2` Relativo al task della Word Sense Inference, utilizzeremo l'euristica della \"frequenza\" per identificare anche i \"Genus Candidates\" quindi i sensi da preferire, perché più ricorrenti\n",
        "nelle varie definizioni. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2412c4ff-47bb-4b61-ad8f-2e6e59be096f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-16T01:57:30.800144+00:00",
          "start_time": "2023-07-16T01:57:30.639325+00:00"
        },
        "noteable": {
          "cell_type": "code"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context:  Counter({'bank': 3, 'go': 2, 'deposit': 1, 'money': 1, 'open': 1, 'new': 1, 'account': 1, 'flower': 1, 'wild': 1, 'full': 1, 'river': 1})\n",
            "Senses for sentence 0 Counter({Synset('rifle.v.02'): 1, Synset('deposit.n.04'): 1, Synset('money.n.03'): 1, Synset('savings_bank.n.02'): 1})\n",
            "Senses for sentence 1 Counter({Synset('unfold.v.04'): 1, Synset('newfangled.s.01'): 1, Synset('rifle.v.02'): 1, Synset('report.v.01'): 1, Synset('deposit.v.02'): 1})\n",
            "Senses for sentence 2 Counter({Synset('flower.n.03'): 1, Synset('wilderness.n.03'): 1, Synset('deposit.v.02'): 1, Synset('entire.s.01'): 1, Synset('river.n.01'): 1})\n"
          ]
        }
      ],
      "source": [
        "from nltk.wsd import lesk\n",
        "\n",
        "\n",
        "def calculate_word_frequencies(sentences):\n",
        "   \n",
        "    freqs = Counter()\n",
        "    # For each sentence in the list, calculate the word frequencies and add them to freqs\n",
        "    for sentence in sentences:\n",
        "        words = preprocess_data(sentence)\n",
        "        freqs += Counter(words)\n",
        "    # Return freqs\n",
        "    return freqs\n",
        "\n",
        "def disambiguate_senses(sentence):\n",
        "    \"\"\"\n",
        "    The function preprocesses the sentence into words, disambiguates the senses of the words using the Lesk algorithm,\n",
        "    and returns a Counter object of the senses.\n",
        "    \"\"\"\n",
        "    # Tokenize the sentence into words -> bag of words\n",
        "    words = preprocess_data(sentence)\n",
        "    # Disambiguate the senses of the words\n",
        "    senses = [lesk(context_sentence=words, ambiguous_word=word) for word in words]\n",
        "    # Remove None values\n",
        "    senses = [sense for sense in senses if sense is not None]\n",
        "    # Return a Counter object of the senses\n",
        "    return Counter(senses)\n",
        "\n",
        "\n",
        "sentences = ['He went to the bank to deposit my money',\n",
        "                        'He went to the bank to open a new bank account',\n",
        "                        'The river bank is full of wild flowers']\n",
        "context = calculate_word_frequencies(sentences)\n",
        "context= context.most_common(15)\n",
        "#convert the context back to a Counter object\n",
        "context = Counter(dict(context))\n",
        "print(\"Context: \", context)\n",
        "for i,sentence in enumerate(sentences):\n",
        "    print(\"Senses for sentence\",i,disambiguate_senses(sentence))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0df291c1",
      "metadata": {},
      "source": [
        "Formalizziamo quanto descritto prima definendo la funzione `generate_genus_candidates`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a80ce6f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged Context : \n",
            " Counter({'bank': 3, 'go': 1, 'deposit': 1, 'money': 1, 'create': 1, 'new': 1, 'account': 1, 'full': 1, 'flower': 1, 'river': 1})\n",
            "Genus Candidates : \n",
            " Counter({Synset('deposit.v.02'): 2, Synset('rifle.v.02'): 1, Synset('deposit.n.04'): 1, Synset('money.n.03'): 1, Synset('savings_bank.n.02'): 1})\n",
            "\n",
            "Top 1 Genus Candidate definition:  put into a bank account\n"
          ]
        }
      ],
      "source": [
        "def generate_genus_candidates(data, genus_n = 5, context_words =25 ):\n",
        "    \"\"\"\n",
        "    This function explores WordNet to find the best sense for a list of sentences.\n",
        "    The function disambiguates the senses of the words in the sentences and counts their frequencies, chooses candidate\n",
        "    \"genus\" senses, \n",
        "\n",
        "    \"\"\"\n",
        "    # Disambiguation and frequency count, only for words in Wordnet\n",
        "    context = calculate_word_frequencies(data)\n",
        "    context= context.most_common(context_words)\n",
        "    #convert the context back to a Counter object\n",
        "    context = Counter(dict(context))\n",
        "    candidate_senses = Counter()\n",
        "    for sentence in data:\n",
        "        candidate_senses += disambiguate_senses(sentence)\n",
        "    # Choose candidate genus\n",
        "    candidate_genus = Counter(dict(candidate_senses.most_common(genus_n)))\n",
        "\n",
        "    return candidate_genus,context\n",
        "\n",
        "sentences = ['He went to the bank to deposit my money asda',\n",
        "                        'He created a new bank account',\n",
        "                        'The river bank is full of flowers']\n",
        "\n",
        "candidate_senses,context = generate_genus_candidates(sentences)\n",
        "print(\"Merged Context : \\n\", context)\n",
        "\n",
        "print(\"Genus Candidates : \\n\", candidate_senses)\n",
        "# fix accesso .. nesting tremendo\n",
        "print(\"\\nTop 1 Genus Candidate definition: \", candidate_senses.most_common(1)[0][0].definition())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be8e4334",
      "metadata": {},
      "source": [
        "Esecuzione dell'algoritmo di Word Sense Induction\n",
        "   - (a) Scelta dei candidati \"genus\" (selezionando i sensi più frequenti).\n",
        "   - (b) Per ogni candidato \"genus\", esecuzione di una ricerca in profondità a partire dal sotto-albero del senso \"genus\" che massimizza la similarità con le definizioni.\n",
        "   - (c) Scelta del senso con la massima similarità tra quelli estratti dai vari sotto-alberi dei candidati \"genus\".\n",
        "\n",
        "\n",
        "All'interno della funzione wsi(), viene chiamata la funzione generate_genus_candidates(data, k) per ottenere i candidati \"genus\" più frequenti dal contesto dei dati. Successivamente, per ogni candidato \"genus\", viene calcolata la similarità con il contesto utilizzando la funzione calc_overlap(sense, context). Infine, i sensi candidati vengono ordinati in base alla similarità e i primi n sensi con la massima similarità vengono restituiti.\n",
        "\n",
        "\n",
        "La similarità coseno è utilizzata nel calcolo dell'overlap tra i vettori di conteggio delle parole dei sensi e del contesto. Funziona efficacemente in questo contesto perché rappresenta una misura di similarità tra i vettori che tiene conto della direzione e della magnitudine dei vettori stessi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "74123837",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({Synset('red.n.01'): 26, Synset('blacken.v.01'): 21, Synset('small.s.08'): 20, Synset('insect.n.01'): 19, Synset('point.n.09'): 13, Synset('fly.v.13'): 11, Synset('worm.n.02'): 9, Synset('luck.n.03'): 8, Synset('coloring_material.n.01'): 7, Synset('normally.r.01'): 7, Synset('well.r.01'): 6, Synset('spot.v.06'): 5, Synset('dot.v.04'): 5, Synset('back.v.10'): 5, Synset('qualify.v.06'): 5})\n",
            "[('insect.n.01', 0.45241571043344786, 'small air-breathing arthropod'), ('red.n.01', 0.3112711298872557, 'red color or pigment; the chromatic color resembling the hue of blood'), ('small.s.08', 0.2879627745785982, 'have fine or very small constituent particles'), ('coloring_material.n.01', 0.11049728283216656, 'any material used for its color'), ('point.n.09', 0.08010206801937156, 'a very small circular shape'), ('normally.r.01', 0.07580202540303349, 'under normal conditions'), ('qualify.v.06', 0.04244013201570598, 'describe or portray the character or the qualities or peculiarities of'), ('luck.n.03', 0.04037543310046244, 'an unknown and unpredictable phenomenon that leads to a favorable outcome'), ('well.r.01', 0.03836122327357236, \"(often used as a combining form) in a good or proper or satisfactory manner or to a high standard (`good' is a nonstandard dialectal variant for `well')\"), ('blacken.v.01', 0.03687143891925662, 'make or become black'), ('spot.v.06', 0.02354718326088262, 'mark with a spot or spots so as to allow easy recognition'), ('dot.v.04', 0.021594148273977452, 'mark with a dot'), ('worm.n.02', 0.015965056026694745, 'a person who has a nasty or unethical character undeserving of respect'), ('fly.v.13', 0.013893619110009466, 'hit a fly'), ('back.v.10', 0.007390247594789609, 'strengthen by providing with a back or backing')]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "\n",
        "def sense_sig_with_freq(sense, levels = 1):\n",
        "    \"\"\"\n",
        "    This function calculates the signature of a sense. \n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the signature from the definition of the sense + examples + synonyms\n",
        "\n",
        "    signature_sentences = [sense.definition()] + sense.examples()\n",
        "    sig = calculate_word_frequencies(signature_sentences)\n",
        "\n",
        "    # Add the synonyms of the sense\n",
        "    synonyms = {lemmatizer.lemmatize(x.lower()) for x in sense.lemma_names() if not '_' in x}\n",
        "    sig += Counter(synonyms)\n",
        "\n",
        "    # Add the word frequencies from the hypernyms, hyponyms, and meronyms of the sense.\n",
        "    # This is done just for the first level of hypernyms, hyponyms, and meronyms.\n",
        "    if levels > 0:\n",
        "        hypernym_sig, hyponym_sig, meronym_sig = Counter(), Counter(), Counter()\n",
        "\n",
        "        for hypernym in sense.hypernyms() + sense.instance_hypernyms():\n",
        "            hypernym_sig += sense_sig_with_freq(hypernym, levels-1)\n",
        "\n",
        "        for hyponym in sense.hyponyms() + sense.instance_hyponyms():\n",
        "            hyponym_sig += sense_sig_with_freq(hyponym, levels-1)\n",
        "\n",
        "        for meronym in sense.part_meronyms() + sense.member_meronyms():\n",
        "            meronym_sig += sense_sig_with_freq(meronym, levels-1)\n",
        "\n",
        "        sig += hypernym_sig\n",
        "        sig += hyponym_sig\n",
        "        sig += meronym_sig\n",
        "\n",
        "    # Return the signature\n",
        "    return sig\n",
        "\n",
        "\n",
        "def calc_overlap(sense, context,levels = 1):\n",
        "\n",
        "    # Get the signature of the sense\n",
        "    sig = sense_sig_with_freq(sense, levels)\n",
        "    # Convert the signature and the context to lists of words\n",
        "    sig_words = list(sig.elements())\n",
        "    context_words = list(context.elements())\n",
        "\n",
        "    sig_string = ' '.join(sig_words)\n",
        "    context_string = ' '.join(context_words)\n",
        "\n",
        "    vectorizer = CountVectorizer().fit([sig_string, context_string])\n",
        "\n",
        "    sig_vector = vectorizer.transform([sig_string]).toarray()\n",
        "    context_vector = vectorizer.transform([context_string]).toarray()\n",
        "\n",
        "    sig_vector = normalize(sig_vector)\n",
        "    context_vector = normalize(context_vector)\n",
        "\n",
        "    # Calculate the cosine similarity between the vectors\n",
        "    similarity = cosine_similarity(sig_vector, context_vector)[0][0]\n",
        "    # Return the similarity\n",
        "    return similarity\n",
        "\n",
        "def wsi(data,n=5, k =25,l = 1):\n",
        "    '''\n",
        "        This function performs Word Sense Induction (WSI).\n",
        "\n",
        "        The function takes a list of candidate senses and a context as input, calculates the overlap    between each candidate sense\n",
        "        and the context using the calc_overlap function, and returns the candidate sense with the   maximum overlap.\n",
        "    '''\n",
        "\n",
        "    candidate_genus,context = generate_genus_candidates(data,n,k)\n",
        "    print(candidate_genus)\n",
        "    sense_similarities = []\n",
        "    for sense in candidate_genus:\n",
        "        similarity = calc_overlap(sense, context,l)\n",
        "        sense_similarities.append((sense, similarity))\n",
        "    # Sort the senses by similarity in descending order and return the top n\n",
        "    sense_similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    sense_similarities = [(x[0].name(), x[1], x[0].definition()) for x in sense_similarities]\n",
        "\n",
        "    return sense_similarities[:n]\n",
        "\n",
        "file_path = './TLN-definitions-23.tsv'\n",
        "\n",
        "data = load_dataset(file_path)   \n",
        "\n",
        "data = defs_df['ladybug'].values.tolist()\n",
        "\n",
        "best_senses = wsi(data,15,25,4)\n",
        "print(best_senses)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa504c0e",
      "metadata": {},
      "source": [
        "### Visualizzazione\n",
        "\n",
        "Visualizziamo i risultati ottenuti.\n",
        "Impostando il parametro l=4 considero una espansione dell'albero su 4 livelli.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4743e4f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({Synset('room.n.04'): 14, Synset('object.v.02'): 14, Synset('unfold.v.04'): 10, Synset('access.v.02'): 9, Synset('give_up.v.11'): 7, Synset('conclude.v.04'): 6, Synset('use.v.03'): 6, Synset('deuce.n.04'): 4, Synset('passing.n.03'): 4, Synset('wall.v.01'): 4, Synset('obstruct.v.02'): 4, Synset('lock.v.08'): 4, Synset('normally.r.01'): 4, Synset('entrance.v.02'): 4, Synset('record.v.01'): 3})\n",
            "Counter({Synset('red.n.01'): 26, Synset('blacken.v.01'): 21, Synset('small.s.08'): 20, Synset('insect.n.01'): 19, Synset('point.n.09'): 13, Synset('fly.v.13'): 11, Synset('worm.n.02'): 9, Synset('luck.n.03'): 8, Synset('coloring_material.n.01'): 7, Synset('normally.r.01'): 7, Synset('well.r.01'): 6, Synset('spot.v.06'): 5, Synset('dot.v.04'): 5, Synset('back.v.10'): 5, Synset('qualify.v.06'): 5})\n",
            "Counter({Synset('feel.v.08'): 13, Synset('forcible.s.01'): 12, Synset('emotional.a.03'): 10, Synset('sense.n.03'): 10, Synset('discomfort.n.02'): 5, Synset('unpleasant.a.01'): 5, Synset('induce.v.02'): 5, Synset('bad.s.03'): 3, Synset('suffer.v.10'): 3, Synset('damage.v.02'): 2, Synset('creature.n.03'): 2, Synset('torso.n.01'): 2, Synset('palpate.v.01'): 2, Synset('negative.s.08'): 2, Synset('leave.v.07'): 2})\n",
            "Counter({Synset('watch.v.03'): 7, Synset('ocular.s.03'): 6, Synset('visualize.v.01'): 5, Synset('stipulate.v.01'): 5, Synset('make.v.15'): 5, Synset('focus.v.05'): 4, Synset('border.v.04'): 4, Synset('miss.v.06'): 4, Synset('eye.v.01'): 4, Synset('hard.s.11'): 4, Synset('specify.v.03'): 4, Synset('impression.n.02'): 4, Synset('intelligibly.r.01'): 3, Synset('clearness.n.02'): 3, Synset('perceive.v.02'): 3})\n",
            "\n",
            "Concept: door\n",
            "1. give_up.v.11; score 0.1845, distance allow the other (baseball) team to score\n",
            "2. unfold.v.04; score 0.1733, distance spread out or open from a closed or folded state\n",
            "3. obstruct.v.02; score 0.1458, distance block passage through\n",
            "4. use.v.03; score 0.1099, distance use up, consume fully\n",
            "5. room.n.04; score 0.1048, distance the people who are present in a room\n",
            "\n",
            "Concept: ladybug\n",
            "1. insect.n.01; score 0.4524, distance small air-breathing arthropod\n",
            "2. red.n.01; score 0.3113, distance red color or pigment; the chromatic color resembling the hue of blood\n",
            "3. small.s.08; score 0.2880, distance have fine or very small constituent particles\n",
            "4. coloring_material.n.01; score 0.1105, distance any material used for its color\n",
            "5. point.n.09; score 0.0801, distance a very small circular shape\n",
            "\n",
            "Concept: pain\n",
            "1. discomfort.n.02; score 0.5286, distance an uncomfortable feeling of mental painfulness or distress\n",
            "2. bad.s.03; score 0.4341, distance feeling physical discomfort or pain (`tough' is occasionally used colloquially for `bad')\n",
            "3. emotional.a.03; score 0.3194, distance of or pertaining to emotion\n",
            "4. forcible.s.01; score 0.2891, distance impelled by physical force especially against resistance\n",
            "5. unpleasant.a.01; score 0.2552, distance disagreeable to the senses, to the mind, or feelings\n",
            "\n",
            "Concept: blurriness\n",
            "1. ocular.s.03; score 0.2576, distance visible; - Shakespeare\n",
            "2. watch.v.03; score 0.2061, distance see or watch\n",
            "3. visualize.v.01; score 0.2055, distance imagine; conceive of; see in one's mind\n",
            "4. make.v.15; score 0.2024, distance make by shaping or bringing together constituents\n",
            "5. perceive.v.02; score 0.1827, distance become conscious of\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file_path = './TLN-definitions-23.tsv'\n",
        "\n",
        "def format_results(results):\n",
        "    output = \"\"\n",
        "    for i, result in enumerate(results, 1):\n",
        "        output += f\"{i}. {result[0]}; score {result[1]:.4f}, distance {result[2]}\\n\"\n",
        "    return output\n",
        "\n",
        "data = load_dataset(file_path)   \n",
        "\n",
        "output = \"\"\n",
        "for column in defs_df.columns:\n",
        "    data = defs_df[column].values.tolist()\n",
        "    best_senses =wsi(data,15,25,4)[:5]\n",
        "    output += f\"\\nConcept: {column}\\n\"\n",
        "    output += format_results(best_senses)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "486cbe3b",
      "metadata": {},
      "source": [
        "## Risultati\n",
        "\n",
        "Attraverso un'analisi qualitativa, è emerso che l'algoritmo utilizzato non è in grado di individuare correttamente il senso desiderato. Un esempio diretto è il caso di \"Door\" che viene\n",
        "associato a qualche senso legato al gioco del baseball, mentre uno dei significati o almeno contesto semantico simile è rappresentato da \"obstruct.v.02\" (anche se la definizione del synset di Wordnet non è molto chiara).\n",
        "\n",
        "Alcune possibili strategie per migliorare le inferenze nel contesto dell'inferenza del senso delle parole:\n",
        "\n",
        "- Ampliamento del contesto: Considerare contesti più ampi potrebbe consentire di ottenere una visione più completa delle parole e dei loro significati. Ad esempio, oltre alle definizioni, potrebbero essere inclusi anche esempi, sinonimi o altri contesti associati.\n",
        "\n",
        "- Considerazione delle relazioni semantiche: Sfruttare le relazioni semantiche tra i sensi delle parole potrebbe essere utile per guidare le inferenze. Ad esempio, invece di considerare solo i sensi più frequenti, potrebbe essere valutato il grado di relazione con il concetto target, come iponimi o iperonimi.\n",
        "\n",
        "- Utilizzo di risorse aggiuntive: Integrare altre risorse linguistiche, come corpus di testi o basi di conoscenza semantiche diverse da WordNet, potrebbe arricchire le informazioni disponibili per le inferenze. Ad esempio, l'utilizzo di ConceptNet potrebbe fornire una prospettiva più contestuale e associativa.\n",
        "\n",
        "\n",
        "WordNet, pur essendo una preziosa risorsa per la conoscenza semantico-lessicale, potrebbe risultare limitata per questo specifico compito. Tra i principali limiti:\n",
        "- Complessità computazionale: L'albero di WordNet è ampio e profondo, con numerosi sensi e relazioni tra di loro. Attraversarlo completamente richiederebbe molto tempo e risorse computazionali, rendendo l'approccio inefficiente per il WSI. Una dimostrazione è il fatto che solo impostando a 4 la profondità di ricerca, i tempi di elaborazione sono aumentati considerevolmente.\n",
        "\n",
        "- Ambiguità dei sensi: Molti sensi in WordNet sono ambigui e possono avere molteplici interpretazioni all'interno di contesti diversi. Attraversare l'albero potrebbe portare a considerare sensi che non sono pertinenti al contesto specifico in cui si sta cercando di inferire il senso corretto.\n",
        "\n",
        "- Scarsa rappresentazione delle relazioni semantiche: WordNet rappresenta principalmente relazioni iponimiche (gerarchiche) tra sensi, ma può mancare di altre relazioni semantiche importanti, come le relazioni associative o contestuali. Queste relazioni possono essere cruciali per la corretta inferenza del senso delle parole in un determinato contesto.\n",
        "\n",
        "- Variazione tra le definizioni dei sensi: Le definizioni fornite in WordNet possono variare notevolmente in termini di stile, contenuto e completezza. Alcune definizioni potrebbero essere più descrittive e utili per il WSI, mentre altre potrebbero essere vaghe o poco informative."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "noteable": {
      "last_delta_id": "bc042520-fd1d-4003-9c5b-399cf809c55a",
      "last_transaction_id": "557cd376-ebef-4b40-a7b4-1440a7f74f92"
    },
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "2b160a08-bab0-5c92-b161-baee2c83d0c9",
        "openai_ephemeral_user_id": "8c6b67a1-c4ed-521a-a369-cb59c592f186"
      }
    },
    "nteract": {
      "version": "noteable@2.9.0"
    },
    "selected_hardware_size": "small"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
